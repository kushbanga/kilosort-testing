{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "from scipy.io import loadmat\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import h5py\n",
    "from scipy.signal import lfilter\n",
    "from scipy.io import loadmat\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../github/pykilosort') #these paths need to be modified\n",
    "sys.path.append('../github/phylib')\n",
    "from pykilosort import Bunch, run, add_default_handler\n",
    "from pykilosort.utils import memmap_large_array, LargeArrayWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_path = Path('D:\\kilosort-testing\\\\100s_data\\\\p1\\\\imec_385_100s.bin') # this path needs to be modified\n",
    "dir_path = dat_path.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_default_handler(level='INFO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Matlab version needs to be run first and the rez output saved at each stage at rez_path under the names rez_preprocess, rez_cluster, rez_learn, rez_split1, rez_split2 and rez_cutoff as well as the binary whitened data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rez_path = Path('D:\\kilosort-testing\\\\100s_data\\\\m1') # needs to be changed\n",
    "test_path = Path('D:\\kilosort-testing\\\\100s_data\\\\python_stages2.5') # needs to be changed\n",
    "dataset_name = 'imec_385_100s' # needs to be changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rez(rez_loc):\n",
    "    try:\n",
    "        rez_file = h5py.File(rez_loc)\n",
    "        main_key = list(rez_file.keys())[-1]\n",
    "        rez = Bunch()\n",
    "        for key in rez_file[main_key].keys():\n",
    "            try:\n",
    "                rez[key] = rez_file[main_key][key][()].squeeze()\n",
    "            except AttributeError:\n",
    "                pass\n",
    "        for key in rez_file[main_key]['ops'].keys():\n",
    "            try:\n",
    "                rez[key] = rez_file[main_key]['ops'][key][()].squeeze()\n",
    "            except AttributeError:\n",
    "                pass\n",
    "    except OSError:\n",
    "        rez_file = loadmat(rez_loc)\n",
    "        main_key = list(rez_file.keys())[-1]\n",
    "        rez = Bunch()\n",
    "    return rez\n",
    "\n",
    "def get_ctx(ctx_loc):\n",
    "    files = os.listdir(ctx_loc)\n",
    "    ctx = Bunch()\n",
    "    for file in files:\n",
    "        if file[-3:] == 'npy':\n",
    "            ctx[file[:-4]] = np.load(ctx_loc / file)\n",
    "    return ctx\n",
    "\n",
    "def transpose_fortran(array):\n",
    "    return np.asfortranarray(array.T)\n",
    "\n",
    "def _save(array, path, name):\n",
    "    np.save(path / name, transpose_fortran(array))\n",
    "    \n",
    "def _save_largearray(array, path, name):\n",
    "    writer = LargeArrayWriter(path / (name + '.dat'), dtype = np.float32, shape = (*array.shape[:-1], -1))\n",
    "    writer.append(np.asfortranarray(array))\n",
    "    writer.close()\n",
    "\n",
    "def setup_dir(path, name):\n",
    "    test_path = path / name / '.kilosort' / dataset_name\n",
    "    if os.path.isdir(test_path):\n",
    "        shutil.rmtree(test_path)\n",
    "    os.makedirs(test_path)\n",
    "    return test_path\n",
    "\n",
    "def test(name, rez, ctx, mapping=None, mapping_axes=None, python_name=None, atol=1e-08):\n",
    "    \n",
    "    if python_name is None:\n",
    "        python_name = name\n",
    "    var_m = np.copy(rez[name]).T\n",
    "    var_p = cp.asnumpy(ctx.intermediate[python_name])\n",
    "    \n",
    "    if mapping_axes is not None:\n",
    "        assert mapping is not None\n",
    "        for i in mapping_axes:\n",
    "            var_m = np.take(var_m, mapping, axis=i)\n",
    "    \n",
    "    return np.allclose(var_m, var_p, atol=atol)\n",
    "\n",
    "def test_abs(name, rez, ctx, mapping=None, mapping_axes=None, python_name=None, atol=1e-08):\n",
    "    \n",
    "    if python_name is None:\n",
    "        python_name = name\n",
    "    var_m = np.abs(np.copy(rez[name]).T)\n",
    "    var_p = np.abs(cp.asnumpy(ctx.intermediate[python_name]))\n",
    "    \n",
    "    if mapping_axes is not None:\n",
    "        assert mapping is not None\n",
    "        for i in mapping_axes:\n",
    "            var_m = np.take(var_m, mapping, axis=i)\n",
    "    \n",
    "    return np.allclose(var_m, var_p, atol=atol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Whitening Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_white_path = setup_dir(test_path, 'test_white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = Path('D:\\kilosort-testing\\\\100s_data\\\\p1\\\\imec_385_100s.bin').parent\n",
    "\n",
    "probe = Bunch()\n",
    "probe.NchanTOT = 385\n",
    "# WARNING: indexing mismatch with MATLAB hence the -1\n",
    "probe.chanMap = np.load(dir_path / 'chanMap.npy').squeeze().astype(np.int64) - 1\n",
    "probe.xc = np.load(dir_path / 'xc.npy').squeeze()\n",
    "probe.yc = np.load(dir_path / 'yc.npy').squeeze()\n",
    "probe.kcoords = np.load(dir_path / 'kcoords.npy').squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0m21:42:20.832 [I] main:56              Loaded raw data with 385 channels, 3000000 samples.\u001b[0m\n",
      "\u001b[0m21:42:20.832 [I] main:56              Loaded raw data with 385 channels, 3000000 samples.\u001b[0m\n",
      "\u001b[0m21:42:20.834 [I] utils:334            Starting step whitening_matrix.\u001b[0m\n",
      "\u001b[0m21:42:20.834 [I] utils:334            Starting step whitening_matrix.\u001b[0m\n",
      "Computing the whitening matrix: 100%|████████████████████████████████████████████████████| 2/2 [00:03<00:00,  1.70s/it]\n",
      "\u001b[0m21:42:30.258 [I] preprocess:275       Computed the whitening matrix.\u001b[0m\n",
      "\u001b[0m21:42:30.258 [I] preprocess:275       Computed the whitening matrix.\u001b[0m\n",
      "\u001b[0m21:42:30.286 [I] utils:344            Step `whitening_matrix` took 9.45s.\u001b[0m\n",
      "\u001b[0m21:42:30.286 [I] utils:344            Step `whitening_matrix` took 9.45s.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ctx = run(dat_path, probe=probe, dir_path=test_white_path.parent.parent, n_channels=385, dtype=np.int16, sample_rate=3e4, stop_after='whitening_matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Nbatch', 'igood', 'Wrot'])"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir = ctx.intermediate\n",
    "ir.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "rez_pre = get_rez(rez_path / 'rez_preprocess.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wrot_python = cp.asnumpy(ir.Wrot)\n",
    "Wrot_matlab = rez_pre.Wrot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(Wrot_python, Wrot_matlab.T, atol=1e-02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pre_path = setup_dir(test_path, 'test_preprocess')\n",
    "\n",
    "rez_preprocess = get_rez(rez_path / 'rez_preprocess.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['Wrot']\n",
    "\n",
    "for variable in variables:\n",
    "    _save(rez_preprocess[variable], test_pre_path, variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "del rez_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe = Bunch()\n",
    "probe.NchanTOT = 385\n",
    "# WARNING: indexing mismatch with MATLAB hence the -1\n",
    "probe.chanMap = np.load(dir_path / 'chanMap.npy').squeeze().astype(np.int64) - 1\n",
    "probe.xc = np.load(dir_path / 'xc.npy').squeeze()\n",
    "probe.yc = np.load(dir_path / 'yc.npy').squeeze()\n",
    "probe.kcoords = np.load(dir_path / 'kcoords.npy').squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0m01:35:48.558 [I] main:56              Loaded raw data with 385 channels, 3000000 samples.\u001b[0m\n",
      "\u001b[0m01:35:48.560 [I] utils:334            Starting step preprocess.\u001b[0m\n",
      "\u001b[0m01:35:48.663 [I] preprocess:396       Loading raw data and applying filters.\u001b[0m\n",
      "Preprocessing: 100%|███████████████████████████████████████████████████████████████████| 46/46 [01:39<00:00,  2.17s/it]\n",
      "\u001b[0m01:37:28.484 [I] utils:344            Step `preprocess` took 99.92s.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ctx = run(dat_path, probe=probe, dir_path=test_pre_path.parent.parent, n_channels=385, dtype=np.int16, sample_rate=3e4, stop_after='preprocess')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rez_pre = get_rez(rez_path / 'rez_preprocess.mat')\n",
    "ir = ctx.intermediate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_python = np.memmap(ir.proc_path, dtype=np.int16, mode=\"r\", order=\"F\")\n",
    "raw_data_matlab = np.memmap(rez_path / 'temp_wh.dat', dtype=np.int16, mode='r', order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nchan = ctx.probe.Nchan\n",
    "NT = ctx.params.NT\n",
    "Nbatch = ir.Nbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tolerance set to 2\n",
      "Batch 13 matches: True\n",
      "Batch 39 matches: True\n",
      "Batch 7 matches: True\n",
      "Batch 32 matches: True\n",
      "Batch 12 matches: True\n",
      "Batch 0 matches: True\n",
      "Batch 24 matches: True\n",
      "Batch 11 matches: True\n",
      "Batch 10 matches: True\n",
      "Batch 27 matches: True\n"
     ]
    }
   ],
   "source": [
    "tol = 2\n",
    "\n",
    "print(f'Tolerance set to {tol}')\n",
    "\n",
    "for i in np.random.choice(Nbatch, 10, replace=False):\n",
    "    batch_python = raw_data_python[NT * Nchan * i:NT * Nchan * (i+1)].reshape((-1, Nchan), order='F')\n",
    "    batch_matlab = raw_data_matlab[NT * Nchan * i:NT * Nchan * (i+1)].reshape((Nchan, -1), order='F').T\n",
    "    print(f'Batch {i} matches: {np.allclose(batch_python, batch_matlab, atol=2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_merge_path = setup_dir(test_path, 'test_merge')\n",
    "\n",
    "rez_learn = get_rez(rez_path / 'rez_learn.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_rez_learn(rez, path):\n",
    "    \n",
    "    variables = ['ccbsort', 'dWU', 'igood', 'iNeigh', 'iNeighPC', 'iorig', 'mu', \n",
    "                 'simScore', 'U', 'U_a', 'U_b', 'UA', 'W', 'W_a', 'W_b',\n",
    "                'WA', 'Wrot', 'wPCA', 'wTEMP']\n",
    "    \n",
    "    for variable in variables:\n",
    "        _save(rez[variable], path, variable)\n",
    "        \n",
    "    _save(rez.ccb, path, 'ccb0')\n",
    "    \n",
    "    _save_largearray(rez.cProj, path, 'fW')\n",
    "    _save_largearray(rez.cProjPC, path, 'fWPC')\n",
    "    \n",
    "    st3 = np.copy(rez.st3)\n",
    "    st3[1,:] = rez.st3[1,:] - 1 # 0-index channels\n",
    "    _save(st3, path, 'st3')\n",
    "    \n",
    "    shutil.copyfile(path / 'fW.dat', path / 'proc.dat') # hack to avoid re-running the pre-processing stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_rez_learn(rez_learn, test_merge_path)\n",
    "del rez_learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe = Bunch()\n",
    "probe.NchanTOT = 385\n",
    "# WARNING: indexing mismatch with MATLAB hence the -1\n",
    "probe.chanMap = np.load(dir_path / 'chanMap.npy').squeeze().astype(np.int64) - 1\n",
    "probe.xc = np.load(dir_path / 'xc.npy').squeeze()\n",
    "probe.yc = np.load(dir_path / 'yc.npy').squeeze()\n",
    "probe.kcoords = np.load(dir_path / 'kcoords.npy').squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0m23:25:29.215 [I] main:56              Loaded raw data with 385 channels, 3000000 samples.\u001b[0m\n",
      "\u001b[0m23:25:29.356 [I] utils:334            Starting step merge.\u001b[0m\n",
      "Finding merges:   0%|                                                                          | 0/357 [00:00<?, ?it/s]../github/pykilosort\\pykilosort\\postprocess.py:426: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Q = (Qi / max(Q00, Q01)).min()\n",
      "Finding merges: 100%|███████████████████████████████████████████████████████████████| 357/357 [00:03<00:00, 114.03it/s]\n",
      "\u001b[0m23:25:32.765 [I] utils:344            Step `merge` took 3.41s.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ctx = run(dat_path, probe=probe, dir_path=test_merge_path.parent.parent, n_channels=385, dtype=np.int16, sample_rate=3e4, stop_after='merge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rez_merge = get_rez(rez_path / 'rez_merge.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the merge phase it is enough to check that st3 is the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st3_matlab = np.copy(rez_merge.st3.T)\n",
    "st3_matlab[:,1] = st3_matlab[:,1] - 1\n",
    "st3_python = cp.asnumpy(ctx.intermediate.st3_m)\n",
    "np.allclose(st3_matlab, st3_python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following clusters were different: []\n"
     ]
    }
   ],
   "source": [
    "ix = np.where(st3_matlab[:,1] - st3_python[:,1] != 0)[0]\n",
    "bad_clusters = np.unique(np.concatenate((st3_python[:,1][ix], st3_matlab[:,1][ix])))\n",
    "print(f'The following clusters were different: {bad_clusters}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ctx\n",
    "del rez_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test First Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split1_path = setup_dir(test_path, 'test_split1')\n",
    "rez_merge = get_rez(rez_path / 'rez_merge.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_rez_merge(rez, path):\n",
    "   \n",
    "    variables = ['ccbsort', 'dWU', 'igood', 'iNeigh', 'iNeighPC', 'iorig', 'mu', \n",
    "                 'simScore', 'U', 'U_a', 'U_b', 'UA', 'W', 'W_a', 'W_b',\n",
    "                'WA', 'Wrot', 'wPCA', 'wTEMP']\n",
    "    \n",
    "    for variable in variables:\n",
    "        _save(rez[variable], path, variable)\n",
    "        \n",
    "    _save(rez.ccb, path, 'ccb0')\n",
    "    \n",
    "    _save_largearray(rez.cProj, path, 'fW')\n",
    "    _save_largearray(rez.cProjPC, path, 'fWPC')\n",
    "    \n",
    "    st3 = np.copy(rez.st3)\n",
    "    st3[1,:] = rez.st3[1,:] - 1 # 0-index channels\n",
    "    _save(st3, path, 'st3')\n",
    "    _save(st3, path, 'st3_m')\n",
    "    \n",
    "    shutil.copyfile(path / 'fW.dat', path / 'proc.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_rez_merge(rez_merge, test_split1_path)\n",
    "del rez_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe = Bunch()\n",
    "probe.NchanTOT = 385\n",
    "# WARNING: indexing mismatch with MATLAB hence the -1\n",
    "probe.chanMap = np.load(dir_path / 'chanMap.npy').squeeze().astype(np.int64) - 1\n",
    "probe.xc = np.load(dir_path / 'xc.npy').squeeze()\n",
    "probe.yc = np.load(dir_path / 'yc.npy').squeeze()\n",
    "probe.kcoords = np.load(dir_path / 'kcoords.npy').squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0m23:25:36.662 [I] main:56              Loaded raw data with 385 channels, 3000000 samples.\u001b[0m\n",
      "\u001b[0m23:25:36.804 [I] utils:334            Starting step split_1.\u001b[0m\n",
      "\u001b[0m23:25:37.532 [I] postprocess:522      Found 0 splits, checked 0/357 clusters, nccg 0\u001b[0m\n",
      "\u001b[0m23:25:42.824 [I] postprocess:522      Found 4 splits, checked 100/361 clusters, nccg 8\u001b[0m\n",
      "\u001b[0m23:25:47.425 [I] postprocess:522      Found 10 splits, checked 200/367 clusters, nccg 9\u001b[0m\n",
      "\u001b[0m23:25:52.510 [I] postprocess:522      Found 13 splits, checked 300/370 clusters, nccg 14\u001b[0m\n",
      "\u001b[0m23:25:58.552 [I] postprocess:732      Finished splitting. Found 19 splits, checked 376/376 clusters, nccg 19\u001b[0m\n",
      "\u001b[0m23:25:58.741 [I] utils:344            Step `split_1` took 21.94s.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ctx = run(dat_path, probe=probe, dir_path=test_split1_path.parent.parent, n_channels=385, dtype=np.int16, sample_rate=3e4, \\\n",
    "          stop_after='split_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rez_split1 = get_rez(rez_path / 'rez_split1.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "st3_matlab = np.copy(rez_split1.st3.T)\n",
    "st3_matlab[:,1] = st3_matlab[:,1] - 1\n",
    "st3_python = cp.asnumpy(ctx.intermediate.st3_s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following clusters were different: [ 44. 173. 195. 246. 357. 358. 359. 360. 361. 362. 363. 365. 369. 371.\n",
      " 372. 373. 374. 375.]\n"
     ]
    }
   ],
   "source": [
    "ix = np.where(st3_matlab[:,1] - st3_python[:,1] != 0)[0]\n",
    "bad_clusters = np.unique(np.concatenate((st3_python[:,1][ix], st3_matlab[:,1][ix])))\n",
    "print(f'The following clusters were different: {bad_clusters}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these differences are just due to labelling, we can try and learn a mapping from the Python clusters to their corresponding Matlab clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping was found\n"
     ]
    }
   ],
   "source": [
    "cluster_mapping = np.zeros((len(bad_clusters), 2), dtype = int)\n",
    "cluster_mapping[:,0] = bad_clusters\n",
    "cluster_mapping[:,1] = -1\n",
    "\n",
    "for i in range(len(bad_clusters)):\n",
    "    ix_p = np.where(st3_python[:,1] == bad_clusters[i])[0]\n",
    "    for j in bad_clusters:\n",
    "        ix_m = np.where(st3_matlab[:,1] == j)[0]\n",
    "        if np.array_equal(ix_p, ix_m):\n",
    "            cluster_mapping[i,1] = j\n",
    "            break\n",
    "\n",
    "mapping_found = False\n",
    "if np.sum(cluster_mapping[:,1] == -1):\n",
    "    print(f\"No mapping found as the following Python clusters can't be matched:\" \\\n",
    "        f\"{cluster_mapping[:,0][np.where(cluster_mapping[:,1] == 0)[0]]}\")\n",
    "elif np.max(st3_matlab[:,1]) != np.max(st3_python[:,1]):\n",
    "    print(\"Some Matlab clusters had no corresponding Python match\")\n",
    "else:\n",
    "    mapping = np.arange(np.max(st3_python[:,1] + 1), dtype=int)\n",
    "    for i in range(cluster_mapping.shape[0]):\n",
    "        mapping[cluster_mapping[i,0]] = cluster_mapping[i,1]\n",
    "    mapping_found = True\n",
    "    print(\"Mapping was found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu matches: True\n",
      "simScore matches: True\n",
      "isplit matches: True\n",
      "iNeighPC matches: True\n"
     ]
    }
   ],
   "source": [
    "print(f\"mu matches: {test('mu', rez_split1, ctx, mapping, [0], 'mu_s')}\")\n",
    "print(f\"simScore matches: {test('simScore', rez_split1, ctx, mapping, [0,1], 'simScore_s')}\")\n",
    "print(f\"isplit matches: {test('isplit', rez_split1, ctx, mapping, [0,1])}\")\n",
    "\n",
    "print(f\"iNeighPC matches: {np.allclose(cp.asnumpy(ctx.intermediate.iNeighPC_s.T), (rez_split1.iNeighPC-1)[mapping])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVD components only match up to an arbitrary sign so we compare absolute values and also use a higher tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W matches: True\n",
      "U matches: True\n",
      "Wphy matches: True\n"
     ]
    }
   ],
   "source": [
    "print(f\"W matches: {test_abs('W', rez_split1, ctx, mapping, [1], 'W_s', atol=1e-05)}\")\n",
    "print(f\"U matches: {test_abs('U', rez_split1, ctx, mapping, [1], 'U_s', atol=1e-05)}\")\n",
    "print(f\"Wphy matches: {test_abs('Wphy', rez_split1, ctx, mapping, [1], atol=1e-05)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iNeigh stores the nearest 32 neighbours for each template. Due to rounding errors this may not always match so we check to see how many nearest neighbours match. iList does exactly the same (repeated variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nearest neighbours that match in iNeigh: 21/32\n",
      "Number of nearest neighbours that match in iList: 21/32\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of nearest neighbours that match in iNeigh: \\\n",
    "{np.min(np.where((rez_split1.iNeigh-1)[mapping] != mapping[cp.asnumpy(ctx.intermediate.iNeigh_s.T)])[1])}/32\")\n",
    "print(f\"Number of nearest neighbours that match in iList: \\\n",
    "{np.min(np.where((rez_split1.iList-1)[mapping] != mapping[cp.asnumpy(ctx.intermediate.iList.T)])[1])}/32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ctx\n",
    "del rez_split1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Second Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split2_path = setup_dir(test_path, 'test_split2')\n",
    "rez_split1 = get_rez(rez_path / 'rez_split1.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_rez_split1(rez, path):\n",
    "   \n",
    "    variables = ['ccbsort', 'dWU', 'igood', 'iList', 'iNeigh', 'iNeighPC', 'iorig', 'isplit', 'mu', \n",
    "                 'simScore', 'U', 'U_a', 'U_b', 'UA', 'W', 'W_a', 'W_b',\n",
    "                'WA', 'Wrot', 'Wphy', 'wPCA', 'wTEMP']\n",
    "    \n",
    "    for variable in variables:\n",
    "        _save(rez[variable], path, variable)\n",
    "        \n",
    "    _save(rez.ccb, path, 'ccb0')\n",
    "    \n",
    "    _save_largearray(rez.cProj, path, 'fW')\n",
    "    _save_largearray(rez.cProjPC, path, 'fWPC')\n",
    "    \n",
    "    st3 = np.copy(rez.st3)\n",
    "    st3[1,:] = rez.st3[1,:] - 1 # 0-index channels\n",
    "    _save(st3, path, 'st3')\n",
    "    _save(st3, path, 'st3_m')\n",
    "    _save(st3, path, 'st3_s1')\n",
    "    \n",
    "    _save(rez.iNeigh, path, 'iNeigh_s')\n",
    "    _save(rez.iNeighPC, path, 'iNeighPC_s')\n",
    "    _save(rez.mu, path, 'mu_s')\n",
    "    _save(rez.simScore, path, 'simScore_s')\n",
    "    _save(rez.U, path, 'U_s')\n",
    "    _save(rez.W, path, 'W_s')\n",
    "    \n",
    "    shutil.copyfile(path / 'fW.dat', path / 'proc.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_rez_split1(rez_split1, test_split2_path)\n",
    "del rez_split1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe = Bunch()\n",
    "probe.NchanTOT = 385\n",
    "# WARNING: indexing mismatch with MATLAB hence the -1\n",
    "probe.chanMap = np.load(dir_path / 'chanMap.npy').squeeze().astype(np.int64) - 1\n",
    "probe.xc = np.load(dir_path / 'xc.npy').squeeze()\n",
    "probe.yc = np.load(dir_path / 'yc.npy').squeeze()\n",
    "probe.kcoords = np.load(dir_path / 'kcoords.npy').squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0m23:26:02.808 [I] main:56              Loaded raw data with 385 channels, 3000000 samples.\u001b[0m\n",
      "\u001b[0m23:26:03.043 [I] utils:334            Starting step split_2.\u001b[0m\n",
      "\u001b[0m23:26:03.308 [I] postprocess:522      Found 0 splits, checked 0/376 clusters, nccg 0\u001b[0m\n",
      "\u001b[0m23:26:07.380 [I] postprocess:522      Found 1 splits, checked 100/377 clusters, nccg 9\u001b[0m\n",
      "\u001b[0m23:26:10.468 [I] postprocess:522      Found 1 splits, checked 200/377 clusters, nccg 10\u001b[0m\n",
      "\u001b[0m23:26:14.338 [I] postprocess:522      Found 1 splits, checked 300/377 clusters, nccg 14\u001b[0m\n",
      "\u001b[0m23:26:19.683 [I] postprocess:732      Finished splitting. Found 3 splits, checked 379/379 clusters, nccg 20\u001b[0m\n",
      "\u001b[0m23:26:19.844 [I] utils:344            Step `split_2` took 16.80s.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ctx = run(dat_path, probe=probe, dir_path=test_split2_path.parent.parent, n_channels=385, dtype=np.int16, sample_rate=3e4, \\\n",
    "          stop_after='split_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rez_split2 = get_rez(rez_path / 'rez_split2.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "st3_matlab = np.copy(rez_split2.st3.T)\n",
    "st3_matlab[:,1] = st3_matlab[:,1] - 1\n",
    "st3_python = cp.asnumpy(ctx.intermediate.st3_s0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following clusters were different: []\n"
     ]
    }
   ],
   "source": [
    "ix = np.where(st3_matlab[:,1] - st3_python[:,1] != 0)[0]\n",
    "bad_clusters = np.unique(np.concatenate((st3_python[:,1][ix], st3_matlab[:,1][ix])))\n",
    "print(f'The following clusters were different: {bad_clusters}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these differences are just due to labelling, we can try and learn a mapping from the Python clusters to their corresponding Matlab clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping was found\n"
     ]
    }
   ],
   "source": [
    "cluster_mapping = np.zeros((len(bad_clusters), 2), dtype = int)\n",
    "cluster_mapping[:,0] = bad_clusters\n",
    "cluster_mapping[:,1] = -1\n",
    "\n",
    "for i in range(len(bad_clusters)):\n",
    "    ix_p = np.where(st3_python[:,1] == bad_clusters[i])[0]\n",
    "    for j in bad_clusters:\n",
    "        ix_m = np.where(st3_matlab[:,1] == j)[0]\n",
    "        if np.array_equal(ix_p, ix_m):\n",
    "            cluster_mapping[i,1] = j\n",
    "            break\n",
    "\n",
    "mapping_found = False\n",
    "if np.sum(cluster_mapping[:,1] == -1) > 0:\n",
    "    print(f\"No mapping found as the following Python clusters can't be matched:\" \\\n",
    "        f\"{cluster_mapping[:,0][np.where(cluster_mapping[:,1] == 0)[0]]}\")\n",
    "elif np.max(st3_matlab[:,1]) != np.max(st3_python[:,1]):\n",
    "    print(\"Some Matlab clusters had no corresponding Python match\")\n",
    "else:\n",
    "    mapping = np.arange(np.max(st3_python[:,1] + 1), dtype=int)\n",
    "    for i in range(cluster_mapping.shape[0]):\n",
    "        mapping[cluster_mapping[i,0]] = cluster_mapping[i,1]\n",
    "    mapping_found = True\n",
    "    print(\"Mapping was found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu matches: True\n",
      "simScore matches: True\n",
      "isplit matches: True\n",
      "iNeighPC matches: True\n"
     ]
    }
   ],
   "source": [
    "print(f\"mu matches: {test('mu', rez_split2, ctx, mapping, [0], 'mu_s')}\")\n",
    "print(f\"simScore matches: {test('simScore', rez_split2, ctx, mapping, [0,1], 'simScore_s')}\")\n",
    "print(f\"isplit matches: {test('isplit', rez_split2, ctx, mapping, [0,1])}\")\n",
    "\n",
    "print(f\"iNeighPC matches: {np.allclose(cp.asnumpy(ctx.intermediate.iNeighPC_s.T), rez_split2.iNeighPC - 1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVD components only match up to an arbitrary sign so we compare absolute values and also use a higher tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W matches: True\n",
      "U matches: True\n",
      "Wphy matches: True\n"
     ]
    }
   ],
   "source": [
    "print(f\"W matches: {test_abs('W', rez_split2, ctx, mapping, [1], 'W_s', atol=1e-05)}\")\n",
    "print(f\"U matches: {test_abs('U', rez_split2, ctx, mapping, [1], 'U_s', atol=1e-05)}\")\n",
    "print(f\"Wphy matches: {test_abs('Wphy', rez_split2, ctx, mapping, [1], atol=1e-05)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iNeigh stores the nearest 32 neighbours for each template. Due to rounding errors this may not always match so we check to see how many nearest neighbours match. iList does exactly the same (repeated variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nearest neighbours that match in iNeigh: 21/32\n",
      "Number of nearest neighbours that match in iList: 21/32\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of nearest neighbours that match in iNeigh: \\\n",
    "{np.min(np.where((rez_split2.iNeigh-1)[mapping] != mapping[cp.asnumpy(ctx.intermediate.iNeigh_s.T)])[1])}/32\")\n",
    "print(f\"Number of nearest neighbours that match in iList: \\\n",
    "{np.min(np.where((rez_split2.iList-1)[mapping] != mapping[cp.asnumpy(ctx.intermediate.iList.T)])[1])}/32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ctx\n",
    "del rez_split2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cutoff_path = setup_dir(test_path, 'test_cutoff')\n",
    "rez_split2 = get_rez(rez_path / 'rez_split2.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_rez_split2(rez, path):\n",
    "   \n",
    "    variables = ['ccbsort', 'dWU', 'igood', 'iList', 'iNeigh', 'iNeighPC', 'iorig', 'isplit', 'mu', \n",
    "                 'simScore', 'U', 'U_a', 'U_b', 'UA', 'W', 'W_a', 'W_b',\n",
    "                'WA', 'Wrot', 'Wphy', 'wPCA', 'wTEMP']\n",
    "    \n",
    "    for variable in variables:\n",
    "        _save(rez[variable], path, variable)\n",
    "        \n",
    "    _save(rez.ccb, path, 'ccb0')\n",
    "    \n",
    "    _save_largearray(rez.cProj, path, 'fW')\n",
    "    _save_largearray(rez.cProjPC, path, 'fWPC')\n",
    "    \n",
    "    st3 = np.copy(rez.st3)\n",
    "    st3[1,:] = rez.st3[1,:] - 1 # 0-index channels\n",
    "    _save(st3, path, 'st3')\n",
    "    _save(st3, path, 'st3_m')\n",
    "    _save(st3, path, 'st3_s1')\n",
    "    _save(st3, path, 'st3_s0')\n",
    "    \n",
    "    _save(rez.iNeigh, path, 'iNeigh_s')\n",
    "    _save(rez.iNeighPC, path, 'iNeighPC_s')\n",
    "    _save(rez.mu, path, 'mu_s')\n",
    "    _save(rez.simScore, path, 'simScore_s')\n",
    "    _save(rez.U, path, 'U_s')\n",
    "    _save(rez.W, path, 'W_s')\n",
    "    \n",
    "    shutil.copyfile(path / 'fW.dat', path / 'proc.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_rez_split2(rez_split2, test_cutoff_path)\n",
    "del rez_split2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe = Bunch()\n",
    "probe.NchanTOT = 385\n",
    "# WARNING: indexing mismatch with MATLAB hence the -1\n",
    "probe.chanMap = np.load(dir_path / 'chanMap.npy').squeeze().astype(np.int64) - 1\n",
    "probe.xc = np.load(dir_path / 'xc.npy').squeeze()\n",
    "probe.yc = np.load(dir_path / 'yc.npy').squeeze()\n",
    "probe.kcoords = np.load(dir_path / 'kcoords.npy').squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0m23:26:23.964 [I] main:56              Loaded raw data with 385 channels, 3000000 samples.\u001b[0m\n",
      "\u001b[0m23:26:24.207 [I] utils:334            Starting step cutoff.\u001b[0m\n",
      "Setting cutoff: 100%|███████████████████████████████████████████████████████████████| 379/379 [00:02<00:00, 186.19it/s]\n",
      "\u001b[0m23:26:26.249 [I] utils:344            Step `cutoff` took 2.04s.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ctx = run(dat_path, probe=probe, dir_path=test_cutoff_path.parent.parent, n_channels=385, dtype=np.int16, sample_rate=3e4, \\\n",
    "          stop_after='cutoff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "rez_cutoff = get_rez(rez_path / 'rez_cutoff.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ths matches: True\n",
      "good matches: True\n",
      "est_contam_rate matches: True\n",
      "st3 matches: True\n"
     ]
    }
   ],
   "source": [
    "print(f\"Ths matches: {np.allclose(rez_cutoff.Ths, ctx.intermediate.Ths)}\")\n",
    "print(f\"good matches: {np.allclose(rez_cutoff.good, ctx.intermediate.good)}\")\n",
    "print(f\"est_contam_rate matches: {np.allclose(rez_cutoff.est_contam_rate, ctx.intermediate.est_contam_rate)}\")\n",
    "\n",
    "st3_matlab = np.copy(rez_cutoff.st3.T)\n",
    "st3_matlab[:,1] = st3_matlab[:,1] - 1\n",
    "st3_python = cp.asnumpy(ctx.intermediate.st3_c)\n",
    "print(f\"st3 matches: {np.allclose(st3_python, st3_matlab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ctx\n",
    "del rez_cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
